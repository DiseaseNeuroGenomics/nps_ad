---
title: "Analysis of NPS/AD"
subtitle: 'Freeze 1 merged h5ad'
author: "Developed by [Gabriel Hoffman](http://gabrielhoffman.github.io/)"
date: "Run on `r Sys.time()`"
documentclass: article
output: 
  html_document:
  toc: true
  smart: false
vignette: >
  %\VignetteIndexEntry{Decorrelate}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
  %\usepackage[utf8]{inputenc}
---


<!--- 

cd /sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/
ml python git
git pull
# rm -rf analysis_freeze1_cache/ analysis_freeze1_files
R --vanilla

system("git pull")
rmarkdown::render("analysis_freeze1.Rmd");


# https://hoffmg01.u.hpc.mssm.edu/nps_ad/


echo "echo \"rmarkdown::render('analysis_freeze1.Rmd');\" | R" > script.sh


bsub -Is -q interactive -R "span[hosts=1]" -W 12:00 -P acc_CommonMind -n 24 bash



ml git
cd ~/build2/dreamlet
git pull
R CMD INSTALL .

npsad:roussoslab

--->



```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  warning=FALSE,
  message=FALSE,
  error = FALSE,
  tidy = FALSE,
  dev = c("png", "pdf"),
  package.startup.message = FALSE,
  cache = TRUE,
  cache.lazy = FALSE)
```

```{r load.packages, cache=FALSE}
# Use cache=FALSE so that package are fully loaded each time
# This ensures that forks within mclapply() have these loaded
# Othewise, mclapply() not have access to these libraries and will fail 
#   unless the libraries are manually loaded within each fork
library(SingleCellExperiment)
library(zellkonverter)
library(DelayedArray)
library(DelayedMatrixStats)
library(HDF5Array)
library(GSEABase)
library(dreamlet)
library(muscat)
library(cowplot)
library(zenith)
library(scater)
library(data.table)
library(S4Vectors)
library(tidyverse)
library(kableExtra)
library(qvalue)
library(corrplot)
library(org.Hs.eg.db)
```


```{r load.data, cache=FALSE}
outfolder = "/sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/freeze1_results/"
datafile = paste0(outfolder, "sceCombine_f1.RDS")

if( file.exists(datafile) ){
  # reading data from RDS is much faster:
  #   especially good for pipeline development
  sceCombine = readRDS( datafile )
}else{
  # read snRNA-seq data with annotations build in
  h5ad_file = "/sc/arion/projects/psychAD/NPS-AD/freeze1_proc/freeze1/211120_NPS-AD_roundMerged_pass2_res20_anno_meta_fixed.h5ad"

  # read raw/* from h5ad file
  sce_in = readH5AD(h5ad_file, use_hdf5=TRUE, raw=TRUE, verbose=TRUE, uns=FALSE)

  # only keep singlets
  sce_in = sce_in[,sce_in$demux_type == "singlet"]

  # extract raw counts
  sceCombine = altExp( sce_in, "raw", withDimnames=TRUE, withColData=TRUE)

  sceCombine = as(sceCombine, "SingleCellExperiment")
  reducedDims(sceCombine) <- reducedDims(sce_in)
  rownames(sceCombine) <- rownames(sce_in)
  rowData(sceCombine) <- rowData(sce_in)

  # collapse GABAergic neurons
  sceCombine$celltype8 = sceCombine$celltype %>%
      as.character %>% 
      recode( 
      "GABAergic SST interneuron" = 'GABAergic neuron',
      "GABAergic VIP interneuron" = 'GABAergic neuron',
      "GABAergic PVALB interneuron" = 'GABAergic neuron') %>% 
      as.factor

  saveRDS(sceCombine, file=datafile)
}
```

Data freeze includes `r length(table(sceCombine$Channel))` samples, `r length(table(sceCombine$round_num))` rounds, `r length(table(sceCombine$batch))` 10X batches, `r length(table(sceCombine$SubID))` donors, and `r format(ncol(sceCombine), big.mark=',')` cells passing QC.

```{r dx}
df = with(colData(sceCombine), unique(data.frame(SubID, dx)))
sort(table(df$dx))
```


# Joint UMAP
```{r umap, dev="png"}
# extract UMAP coordinates and annotations
df = cbind(reducedDim(sceCombine, "X_umap"), colData(sceCombine)[,c("anno", "celltype", 'celltype8', "class", "subtype", "leiden_labels")])
df = data.frame(df)

ggplot(df, aes(V1, V2, color=anno)) + geom_point(size=.05) + theme_classic() + theme(aspect.ratio=1) + guides(colour = guide_legend(override.aes = list(size = 1.5))) + xlab("UMAP1") + ylab("UMAP2")
```

```{r umap2, dev="png"}
ggplot(df, aes(V1, V2, color=celltype)) + geom_point(size=.05) + theme_classic() + theme(aspect.ratio=1) + guides(colour = guide_legend(override.aes = list(size = 1.5))) + xlab("UMAP1") + ylab("UMAP2")
```

```{r umap8, dev="png"}
ggplot(df, aes(V1, V2, color=celltype8)) + geom_point(size=.05) + theme_classic() + theme(aspect.ratio=1) + guides(colour = guide_legend(override.aes = list(size = 1.5))) + xlab("UMAP1") + ylab("UMAP2")
```

```{r umap3, dev="png"}
ggplot(df, aes(V1, V2, color=class)) + geom_point(size=.05) + theme_classic() + theme(aspect.ratio=1) + guides(colour = guide_legend(override.aes = list(size = 1.5))) + xlab("UMAP1") + ylab("UMAP2")
```

```{r umap4, dev="png"}
ggplot(df, aes(V1, V2, color=subtype)) + geom_point(size=.05) + theme_classic() + theme(aspect.ratio=1) + guides(colour = guide_legend(override.aes = list(size = 1.5))) + xlab("UMAP1") + ylab("UMAP2")
```

```{r umap5, dev="png"}
ggplot(df, aes(V1, V2, color=leiden_labels)) + geom_point(size=.05) + theme_classic() + theme(aspect.ratio=1) + guides(colour = guide_legend(override.aes = list(size = 1.5))) + xlab("UMAP1") + ylab("UMAP2")
```

## Summarize cell counts
```{r summarize.cell.counts}
# cells per Channel
colData(sceCombine)$Channel %>% 
  table %>% 
  hist(main=paste0("Cell counts per Channel: mean=", format(mean(.), digits=2), ", median = ", format(median(.), digits=2)))

colData(sceCombine)$SubID %>% 
  table %>% 
  hist(main=paste0("Cell counts per SubID: mean=", format(mean(.), digits=2), ", median = ", format(median(.), digits=2)))

# Number of cells observed per Channel
colData(sceCombine) %>%
  xtabs( ~ Channel + celltype8,.) %>%
  as_tibble %>%
  pivot_longer(cols=Channel) %>%
  ggplot(aes(celltype8, n, fill=celltype8)) + 
    geom_violin(color = NA) + 
    geom_boxplot(width=.1, outlier.size=.1) +
    theme_classic() + 
    theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5),
      legend.position="none") + 
    scale_y_log10() +
    coord_flip() +
    ylab("Number of cells observed per Channel") +
    xlab('')

# Number of cells observed per Subject
colData(sceCombine) %>%
  xtabs( ~ SubID + celltype8,.) %>%
  as_tibble %>%
  pivot_longer(cols=SubID) %>%
  ggplot(aes(celltype8, n, fill=celltype8)) + 
    geom_violin(color = NA) + 
    geom_boxplot(width=.1, outlier.size=.1) +
    theme_classic() + 
    theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5),
      legend.position="none") + 
    scale_y_log10() +
    coord_flip() +
    ylab("Number of cells observed per Subject") +
    xlab('')
```


```{r combineData, message=TRUE}
outfolder = "/sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/freeze1_results/"

# update block size for reading h5ad file from disk
setAutoBlockSize(1e9)

annotation = c("celltype", 'celltype8', "subtype")

for( annot in annotation){
  message(annot)
  # Create pseudo-bulk SingleCellExperiment
  pb <- aggregateToPseudoBulk(sceCombine,
      assay = "X", 
      fun = "sum",
      cluster_id = annot,
      sample_id  = "Channel")

  # Set levels for Dx2
  lvls = sort(unique(as.character(colData(pb)$dx)))
  lvls = lvls[-which(lvls=="Control")]
  colData(pb)$dx = factor(colData(pb)$dx, c("Control", lvls))

  file = paste0(outfolder, 'pbObj_', annot, '.RDS')
  saveRDS(pb, file=file)
}
rm(pb)
```

```{r read.pb}
annot = "celltype8"
file = paste0(outfolder, 'pbObj_', annot, '.RDS')
pbObj = readRDS(file)
```


## Summarize read counts
```{r summarize.read.counts}
# extract read counts for each Channel
df_counts = lapply( assayNames(pbObj), function(x){
  data = assay(pbObj, x)

  data.frame(celltype = x, ID = colnames(data), readCounts = colSums(data))

})
df_counts = do.call(rbind, df_counts)

ggplot(df_counts, aes(celltype, readCounts, fill=celltype)) +  
    geom_violin(color = NA) + 
    geom_boxplot(width=.1, outlier.size=.1) +
    theme_classic() + 
    theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5),
      legend.position="none") + 
    scale_y_log10() +
    coord_flip() +
    ylab("Number of reads observed for each Channel") +
    xlab('') +
    ggtitle('Reads per cell cluster for each Channel')

# extract cell counts
df_rate = cellCounts(pbObj) %>%
            as.data.frame %>%
            mutate(ID = rownames(.))  %>% 
            pivot_longer(cols=-ID, values_to="ncells", names_to="celltype")

# plot reads per cell
inner_join(df_counts, df_rate, by=c("celltype", "ID")) %>%
  ggplot(aes(celltype, readCounts/ncells, fill=celltype)) +  
    geom_violin(color = NA) + 
    geom_boxplot(width=.1, outlier.size=.1) +
    theme_classic() + 
    theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5),
      legend.position="none") + 
    scale_y_log10() +
    coord_flip() +
    ylab('Reads per cell') +
    xlab('') +
    ggtitle('Reads per cell for each Channel')
```

## examine total reads and reads per cluster





## Cell type specificity
```{r cellTypeSpecificity}
df = cellTypeSpecificity( pbObj )

plotViolin(df)
```

### Show cell markers
```{r cellMarkers}
library(org.Hs.eg.db)
# /sc/arion/projects/CommonMind/leed62/app/leetools/pegasus/human_brain_cell_markers.json
# /sc/arion/projects/CommonMind/leed62/app/leetools/pegasus/human_brain_immune_cell_markers.json
# /sc/arion/projects/CommonMind/leed62/app/leetools/pegasus/human_immune_cell_markers.json
genes = c('RBFOX3', 'MEG3', 'SLC17A7',
'RBFOX3', 'MEG3', 'GAD1', 'GAD2', 'GRIK1',
'SST',
'PVALB',
'VIP',
'SLC1A3', 'GFAP', 'APOE', 'SLC1A2', 'SLC14A1',
'PLP1', 'MAG', 'MBP',
'PDGFRA', 'VCAN',
'FLT1', 'CLDN5',
'PDGFRB',
'TGFBR1', 'DOCK8', 'CD74', 'CSF1R', 'MS4A6A', 'PLXDC2')
 
df_genes = AnnotationDbi::select(org.Hs.eg.db, genes, "ENSEMBL", "SYMBOL")

df_sub = df[rownames(df) %in% df_genes$ENSEMBL,]
idx = match(rownames(df_sub), df_genes$ENSEMBL)
rownames(df_sub) = df_genes$SYMBOL[idx]

plotPercentBars(df_sub, genes=unique(genes))
```

```{r heatmap, fig.height=7, fig.width=7}
dreamlet::plotHeatmap(df_sub, genes=unique(genes))
```


```{r Dx.summary}
df = unique(data.frame(Dx = pbObj$dx, Donor = pbObj$SubID))

sort(table(df$dx), decreasing=TRUE) %>% kbl() %>% kable_styling(full_width=FALSE)
```

```{r voom}
# Normalize and apply voom
res.proc = processAssays( pbObj, ~ (1|SubID) + (1|batch) + (1|round_num) + (1|HTO) + (1|Institution), 
  min.cells = 5,
  min.count = 10, 
  # pmetadata = df_collapse,  
  # pkeys=c('ID', 'anno'),
  BPPARAM = SnowParam(6, progressbar=TRUE))
  
res.proc
```

```{r voom.plot, fig.height=10, fig.width=10, cache=TRUE}
plotVoom( res.proc )
```


```{r voom.plot_sub, fig.height=4, fig.width=10, cache=TRUE}
plotVoom( res.proc[7:9] )
```


```{r plot.sex} 
df_gene =  AnnotationDbi::select(org.Hs.eg.db, keys=c("XIST", "UTY"), keytype="SYMBOL", columns="ENSEMBL")

df_sex = lapply( names(res.proc), function(CT){
  geneExpr = res.proc[[CT]]
  df = NULL
  if( sum(df_gene$ENSEMBL %in% rownames(geneExpr)) == 2){  
    df = data.frame(cellType = CT, IDS = colnames(geneExpr$E), XIST = geneExpr$E[df_gene$ENSEMBL[1],], UTY = geneExpr$E[df_gene$ENSEMBL[2],])
  }
  df
})
df_sex = do.call(rbind, df_sex)

df_sex = merge(df_sex, colData(pbObj)[,"Sex",drop=FALSE], by.x="IDS", by.y="row.names")

ggplot(as.data.frame(df_sex), aes(XIST, UTY, color=Sex)) + geom_point() + theme_classic() + facet_wrap(~cellType) + theme(aspect.ratio=1)
```

Sex expression based on XIST and UTY
```{r sex.combine, eval=FALSE}
# get total reads
totalReads = DelayedMatrixStats::colSums2(assay(sceCombine, "X"))
df_totalReads = data.frame(totalReads, Channel=sceCombine$Channel) %>%
  group_by(Channel) %>%
  summarise(LibSize = sum(totalReads))

rm(totalReads)
gc()

# sum across cells for each Donor
counts = assay(sceCombine[df_gene$ENSEMBL,], "X")

setAutoBlockSize(1e8)
grid = colAutoGrid(counts, ncol=100000)

df = dreamlet:::colsum_fast(counts, droplevels(sceCombine$Channel), grid=grid)

# merge expression with metadata
df_meta_uniq = unique(colData(sceCombine)[,c("Channel", "Sex")])
df_meta_uniq = merge(df_meta_uniq, df_totalReads, by="Channel")

df_sex = merge(df_meta_uniq, as.matrix(t(df)), by.x="Channel", by.y="row.names")

rm(df, df_meta_uniq)
gc()

colnames(df_sex)[colnames(df_sex) == df_gene$ENSEMBL[1]] = df_gene$SYMBOL[1] 
colnames(df_sex)[colnames(df_sex) == df_gene$ENSEMBL[2]] = df_gene$SYMBOL[2]

df_sex2 = df_sex %>% 
          group_by(Channel) %>%
          summarise(Sex = unique(Sex),
                    UTY = log2(sum(UTY) + 0.25) - log2(sum(LibSize)) + log2(1e6),
                    XIST= log2(sum(XIST) + 0.25) - log2(sum(LibSize)) + log2(1e6))

ggplot(df_sex2, aes(XIST, UTY, color=Sex)) + geom_point() + theme_classic() + scale_color_manual(values=c("red", "blue", "green"))
```




```{r varPart.plain}
form = ~ (1|SubID)

res.vp = fitVarPart(res.proc, form, BPPARAM = SnowParam(6, progressbar=TRUE))
```

```{r vp.plot.plain, fig.height=15, fig.width=10, cache=FALSE}
plotVarPart( sortCols(res.vp) )
```

```{r varPart}
form = ~ (1|SubID) + (1|batch) + (1|round_num) + (1|HTO) + (1|dx) + (1|Sex) + (1|Institution) + scale(Age)

res.vp = fitVarPart(res.proc, form, BPPARAM = SnowParam(6, progressbar=TRUE))
```

```{r vp.plot, fig.height=15, fig.width=10, cache=TRUE}

colnames(res.vp) = gsub("scale\\.", "", colnames(res.vp))
colnames(res.vp) = gsub("\\.", "", colnames(res.vp))
colnames(res.vp) = gsub("SubID", "Donor", colnames(res.vp))

plotVarPart( sortCols(res.vp), label.angle=45 )
```

```{r vp.plot_sub, fig.height=4, fig.width=10, cache=TRUE}
idx = res.vp$assay %in% c('GABAergic neuron', 'Glutamatergic neuron', 'Microglia')
plotVarPart( sortCols(res.vp[idx,]), label.angle=70 )
```



### Examine variancePartition results
```{r vp.examine, fig.height=3, fig.width=7}
CT = "Astrocyte"

i = 1:3
df = sortCols(res.vp)[res.vp$assay == CT,]
rownames(df) = df$gene
i = c(i, which.max(df$Donor), which.max(df$Batch), which.max(df$Residuals))

plotPercentBars( data.frame(df[i,-c(1,2)])) + ggtitle(CT)
```

Examples

```{r vp.examine2, fig.height=6, fig.width=8, cache=TRUE}      
figList = lapply( df$gene[i], function(geneName){
  df = merge( as.data.frame(t(assay(res.proc, CT)$E[geneName,,drop=FALSE])), colData(res.proc), by="row.names")

  plotStratifyBy(df, 'SubID', geneName, colorBy=NULL, main=geneName) + theme(aspect.ratio=1)
})
plot_grid( plotlist=figList, nrow=2 )
```

## Batch effects and gen sets
```{r DE.batch}
library(zenith)
go.gs = get_GeneOntology(to="ENSEMBL")

coef = "batch"
n_genes_min = 10
geneSets = go.gs

res = lapply( unique(res.vp$assay), function(key){
  
  # subset by assay
  df = res.vp[res.vp$assay == key,]

  # get variance statistic
  statistic = df[,coef]
  names(statistic) = df$gene

  # convert GeneSetCollection to list
  geneSets.lst = recodeToList( geneSets )

  # Map from Ensembl genes in geneSets_GO to 
  # from trimmed Ensembl names from RNA-seq data 
  index = ids2indices( geneSets.lst, names(statistic))
     
  # filter by size of gene set
  index = index[vapply(index, length, FUN.VALUE=numeric(1)) >= n_genes_min]

  res = cameraPR( statistic, index, use.ranks=TRUE)

  DataFrame( assay = key, Geneset = rownames(res), res)
})
res = do.call(rbind, res)

res$FDR = p.adjust(res$PValue, "fdr")

# table(res$FDR < 0.05)
```






# Correlation with and between donors
```{r within_btw, fig.height=10, fig.width=10}
source("/sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/common_analyses.R")

eval_within_across_donor( res.proc, "SubID" )
```


```{r dreamlet.fit}
form = ~ Sex + (1|SubID) + (1|batch) + (1|round_num) + (1|HTO) + (1|Institution) + dx + scale(Age)

fit.dl = dreamlet( res.proc, form, BPPARAM=SnowParam(6))

file = paste0(outfolder, "fit.dl.RDS")
saveRDS( fit.dl, file=file)
```

```{r write.residuals, eval=TRUE}
form = ~ Sex + (1|batch) + (1|round_num) + (1|HTO) + (1|Institution) + dx #+ scale(Age) 

fit.for.resid = dreamlet( res.proc, form, BPPARAM=SnowParam(6))

# extract residuals for each assay
resMatList = lapply( assayNames(fit.for.resid), function(CT){

  # get residuals for assay CT
  resMat = residuals(assay(fit.for.resid, CT))

  # extra colData for there samples
  idx = match(colnames(resMat), rownames(colData(res.proc)))
  info = droplevels(colData(res.proc)[idx,])
  # identical(colnames(resMat), rownames(info))

  # for each Donor, report mean expression
  resMatCollapse = lapply( unique(info$SubID), function(grpid){
    idx = which(info$SubID == grpid)

    rowMeans(resMat[,idx,drop=FALSE])
    })
  resMatCollapse = do.call(cbind, resMatCollapse)
  colnames(resMatCollapse) = unique(info$SubID)

  resMatCollapse
})
names(resMatList) = assayNames(fit.for.resid)

library(R.utils)
outPath = paste0("/sc/arion/projects/CommonMind/hoffman/NPS-AD/work/residuals/", Sys.Date())
if(! dir.exists(outPath) ){
  dir.create(outPath)
}

for( CT in names(resMatList) ){
  file = paste0(outPath, "/", gsub(' ', '_',CT), '.tsv')
  data = format(resMatList[[CT]], digits=5)
  write.table( data, file=file, quote=FALSE, sep="\t")
  gzip(file, overwrite=TRUE)
}
```



```{r de.summary}
# library(dreamlet)
# fit.dl = readRDS("/sc/arion/projects/CommonMind/hoffman/NPS-AD/work/fit.dl.RDS")
# pbObj = readRDS("/sc/arion/projects/CommonMind/hoffman/NPS-AD/work/pbObj_v2.RDS")

coefs = c('dxAD', 'dxBP', 'dxSCZ')

tabLst = lapply( coefs, function(key){
  tab = topTable(fit.dl, coef=key, number=Inf)

  tab %>% 
    as_tibble %>% 
    group_by(assay) %>% 
    summarise( coef = key, 
      nGenes = length(adj.P.Val), 
      nDE = sum(adj.P.Val < 0.05),
      pi1 = 1 - qvalue(P.Value)$pi0)
  })
tab = do.call(rbind, tabLst)

as.data.frame(tab)
```

```{r de.plots}
ggplot(tab, aes(assay, nGenes, fill=assay)) + geom_bar(stat="identity") + facet_wrap(~coef) + theme_classic() + theme(aspect.ratio=1, legend.position="none", axis.text.x = element_text(angle = 45, vjust=1, hjust=1) )

ggplot(tab, aes(assay, nDE, fill=assay)) + geom_bar(stat="identity") + facet_wrap(~coef) + theme_classic() + theme(aspect.ratio=1, legend.position="none", axis.text.x = element_text(angle = 45, vjust=1, hjust=1) )

ggplot(tab, aes(assay, pi1, fill=assay)) + geom_bar(stat="identity") + facet_wrap(~coef) + theme_classic() + theme(aspect.ratio=1, legend.position="none", axis.text.x = element_text(angle = 45, vjust=1, hjust=1) )
```

# Volcanos
```{r volcanos.1, fig.width=7, fig.height=12}
plotVolcano( fit.dl, coef = coefs[1], nGenes=0 ) + ggtitle(coefs[1])
```

```{r volcanos.2, fig.width=7, fig.height=12}
plotVolcano( fit.dl, coef = coefs[2], nGenes=0 ) + ggtitle(coefs[2])
```

```{r volcanos.3, fig.width=7, fig.height=12}
plotVolcano( fit.dl, coef = coefs[3], nGenes=0 ) + ggtitle(coefs[3])
```

# Cross-disease signature analysis
```{r compare.signatures, fig.width=9, fig.height=9}
# get one data.frame with all differential expression scores
df = lapply( coefs, function(coef){
  data.frame( coef=coef, topTable(fit.dl, coef=coef, number=Inf))
})
df = do.call(rbind, df)

# dcast as wide matrix
df2 = reshape2::dcast(df, ID ~ coef + assay , value.var="z.std")

colnames(df2) = gsub("^dx", '', colnames(df2))
C = cor(df2[,-1], use='pairwise.complete.obs')

col = colorRampPalette(c("blue3", "white","red3"))(200)

corrplot(C, col=col, tl.col="black")

corrplot(C, order="hclust", col=col, tl.col="black")
```

### Decompose differential expression: cell type by disease
```{r vp.z.std}
df_ids = lapply(strsplit(colnames(df2)[-1], "_"), function(x){
  data.frame(Dx = x[1], CellType = x[2])
  })
df_ids = do.call(rbind, df_ids)

df2_zeros = df2

df2_elist = list(E = df2[,-1], weights = matrix(1, nrow(df2), ncol(df2)-1))
rownames(df2_elist$E) = df2[,1]
df2_elist = new("EList", df2_elist)

keep = apply(df2, 1, function(x) sum(!is.na(x)) > 22)
df2_elist = df2_elist[keep,]
idx = is.na(df2_elist$E)
df2_elist$E[idx] = 0
df2_elist$weights[idx] = 1/1e4

df_vp = fitExtractVarPartModel( df2_elist, ~ Dx + CellType, df_ids, colinearityCutoff=1)

plotVarPart(df_vp)
```

# show top examples
```{r forest.summary}
gene = rownames(df_vp)[which.max(df_vp$Dx)]
fig1 = plotForest( fit.dl, gene, coef = coefs[1]) 
fig2 = plotForest( fit.dl, gene, coef = coefs[2]) + ggtitle('')
fig3 = plotForest( fit.dl, gene, coef = coefs[3]) + ggtitle('')
plot_grid(fig1, fig2, fig3, ncol=1, align="hv", axis="tblr")

gene = rownames(df_vp)[which.max(df_vp$CellType)]
fig1 = plotForest( fit.dl, gene, coef = coefs[1]) 
fig2 = plotForest( fit.dl, gene, coef = coefs[2]) + ggtitle('')
fig3 = plotForest( fit.dl, gene, coef = coefs[3]) + ggtitle('')
plot_grid(fig1, fig2, fig3, ncol=1, align="hv", axis="tblr")

gene = rownames(df_vp)[which.max(df_vp$Residuals)]
fig1 = plotForest( fit.dl, gene, coef = coefs[1]) 
fig2 = plotForest( fit.dl, gene, coef = coefs[2]) + ggtitle('')
fig3 = plotForest( fit.dl, gene, coef = coefs[3]) + ggtitle('')
plot_grid(fig1, fig2, fig3, ncol=1, align="hv", axis="tblr")
```




# zenith for gene set analysis
```{r zenith}
# Load Gene Ontology database 
go.gs = get_GeneOntology()

ngenes = sapply(go.gs, function(gs) length(geneIds(gs)))
go.gs = go.gs[(ngenes > 20) & (ngenes < 2000)]

coefs = c('dxAD', 'dxBP', 'dxSCZ')

res.gsa = lapply( coefs, function(key){

  # check inter.gene.cor=NA
  zenith_gsa(fit.dl, coefs=key, go.gs, inter.gene.cor=.01)
})
names(res.gsa) = coefs
res.gsa_cat = do.call(rbind, res.gsa)
```

```{r zenith.heatmap.1, fig.width=7, fig.height=12}
fig = plotZenithResults(res.gsa[[1]], 3, 1) + ggtitle(names(res.gsa)[1])
```

```{r zenith.heatmap.2, fig.width=7, fig.height=12}
fig = plotZenithResults(res.gsa[[2]], 3, 1) + ggtitle(names(res.gsa)[3])
```

```{r zenith.heatmap.3, fig.width=7, fig.height=12}
fig = plotZenithResults(res.gsa[[3]], 3, 1) + ggtitle(names(res.gsa)[3])
```


# MASH
```{r mash}
mashList = lapply( coefs, function(coef){
  run_mash( fit.dl, coef)
  })
names(mashList) = coefs
``` 

```{r mash_downstream}
library(mashr)

lapply( coefs, function(coef){
  table( apply(get_lfsr(mashList[[coef]]$model), 1, min, na.rm=TRUE) < 0.05)
})

df_lfsr = lapply( coefs, function(coef){
  nDE = apply(get_lfsr(mashList[[coef]]$model), 2, function(x) sum(x < 0.05, na.rm=TRUE))
  data.frame(Dx = coef, CellType = names(nDE), nDE)
})
df_lfsr = do.call(rbind, df_lfsr)

ggplot(df_lfsr, aes(CellType, nDE, fill=CellType)) + geom_bar(stat="identity") + facet_wrap(~Dx) + theme_classic() + theme(aspect.ratio=1, legend.position="none", axis.text.x = element_text(angle = 45, vjust=1, hjust=1) )
```

```{r pi1}
df_pi = lapply( coefs, function(coef){
  df = get_estimated_pi(mashList[[coef]]$model)
  data.frame(Component = names(df), pi = df, coef=coef)
})
df_pi = do.call(rbind, df_pi)

ggplot(df_pi, aes(Component, pi, fill=coef)) + 
  geom_bar(stat="identity", position="dodge") + 
  theme_classic() +
  theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5)) +
  coord_flip() +
  scale_y_continuous(limits=c(0, 1), expand=c(0,0)) +
  ylab("Posterior probability") +
  ggtitle("Sharing from mashr") +
  scale_fill_brewer(palette="Set1")
# m =  mashList[[3]]$model

# pi1 = get_estimated_pi(m)[-1]
# C = lapply( 1:length(pi1), function(i){
#   m$fitted_g$Ulist[[i]] * pi1[i]
# })

# Reduce("+", C)
```

```{r sharing.freq}
# allow NA values
get_n_significant_conditions_na = function (m, thresh = 0.05, conditions = NULL, sig_fn = get_lfsr){
    if (is.null(conditions)) {
        conditions = 1:mashr:::get_ncond(m)
    }
    return(apply(sig_fn(m)[, conditions, drop = FALSE] < thresh, 
        1, sum, na.rm=TRUE))
}

df_sharing = lapply( coefs, function(coef){
  df = get_n_significant_conditions_na(mashList[[coef]]$model)
  data.frame(table(df), coef=coef)
})
df_sharing = do.call(rbind, df_sharing)

ggplot(df_sharing, aes(df, Freq, fill=coef)) + 
  geom_bar(stat="identity", position="dodge") + 
  theme_classic() +
  theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5)) +
  scale_y_continuous(limits=c(0, NA), expand=c(0,0)) +
  ylab("Number of genes") +
  xlab("Number of cell types")  +
  ggtitle("Frequency of eQTL sharing") +
  scale_fill_brewer(palette="Set1")
```


```{r upsetr}

# UpsetR plot
library(UpSetR)

res.upset = lapply( coefs, function(coef){

  m = mashList[[coef]]$model

  listInput = lapply( colnames(m$result$PosteriorMean), function(cond)
                  get_significant_results(m, conditions=cond))
  names(listInput) = colnames(m$result$PosteriorMean)

  fromList(listInput)
})
names(res.upset) = coefs

nsets = max(sapply(res.upset, ncol))

upset(res.upset[[1]], order.by = "freq", nsets=nsets)
upset(res.upset[[2]], order.by = "freq", nsets=nsets)
upset(res.upset[[3]], order.by = "freq", nsets=nsets)
```

## Cross-disease signature analysis
```{r compare.signatures.mashr, fig.width=9, fig.height=9}
# get one data.frame with all differential expression scores
df = lapply( coefs, function(coef){
  beta = get_pm(mashList[[coef]]$model) / get_psd(mashList[[coef]]$model)
  reshape2::melt(data.frame(coef=coef, ID = rownames(beta), beta), id.vars=c("coef", "ID"))
})
df = do.call(rbind, df)

# dcast as wide matrix
df2 = reshape2::dcast(df, ID ~ coef + variable , value.var="value")

colnames(df2) = gsub("^dx", '', colnames(df2))
C = cor(df2[,-1], use='pairwise.complete.obs')

col = colorRampPalette(c("blue3", "white","red3"))(200)

corrplot(C, col=col, tl.col="black")

corrplot(C, order="hclust", col=col, tl.col="black")
```

### Mashr joint analysis
```{r mashr.joint}
# run mashr combining across models
res.joint = run_mash( fit.dl, coefs)
```

Make more plots here
```{r mashr.joint.plots}
```


## zenith
```{r zenith.mash}
res_zenith = lapply( coefs, function(coef){
  zenith_gsa(mashList[[coef]], go.gs)
})
names(res_zenith) = coefs
```

```{r zenith.heatmap.mash.1, fig.width=7, fig.height=12}
fig = plotZenithResults(res_zenith[[1]], 3, 1) + ggtitle(names(res_zenith)[1])
```

```{r zenith.heatmap.mash.2, fig.width=7, fig.height=12}
fig = plotZenithResults(res_zenith[[2]], 3, 1) + ggtitle(names(res_zenith)[3])
```

```{r zenith.heatmap.mash.3, fig.width=7, fig.height=12}
fig = plotZenithResults(res_zenith[[3]], 3, 1) + ggtitle(names(res_zenith)[3])
```





# Cell type composition

## Plot cell type composition
```{r plotCellComposition, fig.height=20, fig.width=5, eval=FALSE}
tab = sort(table(pbObj$dx))
tab = tab[tab<40][1:4]

figLst = lapply(names(tab), function(lvl){

  idx = which(pbObj$dx == lvl)
  idx = idx[!is.na(idx)]

  fig = plotCellComposition(pbObj[,idx]) + ggtitle(lvl) 

  if( lvl != names(tab)[which.max(tab)] ){
    fig = fig + theme(legend.position="none")
  }
  fig
})

plot_grid(plotlist=figLst, rel_heights= tab[ids], ncol=1, align="hv", axis="tblr")
```


```{r plotCellComposition.summary, fig.height=1, fig.width=6}
df_cellCount = do.call(rbind, int_colData(pbObj)$n_cells)

plotCellComposition( t(colSums(df_cellCount)))
```




## Partition variation in cell type composition
```{r cellTypeCompositionVarPart, fig.height=4, fig.width=6}
# Add dream here
# deal with NA's here 
form = ~ (1|SubID) + (1|batch) + (1|round_num) + (1|HTO) + (1|Sex) + (1|dx) + (1|Institution) + scale(Age) 

i = with(as.data.frame(colData(pbObj)), !is.na(dx) & !is.na(Age) & !is.na(Sex))

library(crumblr)

# crumblr transform cell counts
cobj = crumblr(cellCounts(pbObj[,i]))

# variance partitioning analysis
df_vp = fitExtractVarPartModel(cobj, form, as.data.frame(colData(pbObj[,i])))

# rownames(df_vp) = df_vp$assay
colnames(df_vp) = gsub("scale\\.", "", colnames(df_vp))
colnames(df_vp) = gsub("\\.", "", colnames(df_vp))
colnames(df_vp) = gsub("SubID", "Donor", colnames(df_vp))

plotPercentBars( df_vp )
```

```{r pca}
# compute cell fractions
fractions = t(apply(cellCounts(pbObj[,i]), 1, function(x){
  x = x+1
  x / sum(x)
}))

# correlation between cell types
plotCorrMatrix( cor(t(vst(cobj))) )

# PCA on VST
res = prcomp( t(vst(cobj)), scale.=FALSE )

# merge with subject metadata
df_pca = merge(as.data.frame(res$x), colData(pbObj[,i]), by="row.names")
df_pca = merge(df_pca, fractions, by.x="Row.names", by.y="row.names")

fig = df_pca %>%
      ggplot(aes(PC1, PC2, color=dx)) + 
        geom_point() +
        theme_classic() +
        theme(aspect.ratio=1, legend.position="right")

ggsave("test.png", fig)


df = cor(df_pca[,2:3], df_pca[,c( 'Age', colnames(fractions))], method="sp")
df = data.frame(variable = colnames(df), t(df))

df %>%
  pivot_longer(cols=-"variable", names_to="PC") %>%
  ggplot(aes(PC, variable, fill=value)) +
      geom_tile() +
      theme_classic() +
      theme(aspect.ratio=5) +
      scale_fill_gradient2(name = "Correlation", low="blue", mid="white", high="red", limits=c(-1, 1))
```

## Perform statistical tests
For each cell type
```{r cellTypeCompositionTest}
form = ~ (1|SubID) + (1|batch) + (1|round_num) + (1|HTO) + (1|Sex) + (1|Institution) + dx + scale(Age) 

fit = dream(cobj, form, as.data.frame(colData(pbObj[,i])))
fit = eBayes(fit)

topTable(fit, coef=coefs[1], number=Inf, sort.by="none")[,1:5] %>% 
  kable(digits=c(2, 2, 2, 3, 3, 2, 2), caption=coefs[1]) %>% 
  kable_classic(full_width = FALSE, html_font = "Cambria")

topTable(fit, coef=coefs[2], number=Inf, sort.by="none")[,1:5] %>%
  kable(digits=c(2, 2, 2, 3, 3, 2, 2), caption=coefs[2]) %>% 
  kable_classic(full_width = FALSE, html_font = "Cambria")

topTable(fit, coef=coefs[3], number=Inf, sort.by="none")[,1:5] %>% 
  kable(digits=c(2, 2, 2, 3, 3, 2, 2), caption=coefs[3]) %>% 
  kable_classic(full_width = FALSE, html_font = "Cambria")
```


### Collapse neuronal subtypes
```{r cellTypeCompositionVarPart.neuron, fig.height=4, fig.width=6}
# Add dream here
# deal with NA's here 
form = ~ (1|SubID) + (1|batch) + (1|round_num) + (1|HTO) + (1|Sex) + (1|dx) + (1|Institution) + scale(Age) 

i = with(colData(pbObj), !is.na(dx) & !is.na(Age) & !is.na(Sex))

df_counts = as.data.frame(cellCounts(pbObj[,i]))
idx = grep("GABA|Gluta", colnames(df_counts))

# include summed neurons
df_counts$Neurons = rowSums(df_counts[,idx])

# drop split neurons
df_counts = df_counts[,-idx]

cobj = crumblr(as.matrix(df_counts))
df_vp = fitExtractVarPartModel(cobj, form, as.data.frame(colData(pbObj[,i])))

# rownames(df_vp) = df_vp$assay
colnames(df_vp) = gsub("scale\\.", "", colnames(df_vp))
colnames(df_vp) = gsub("\\.", "", colnames(df_vp))
colnames(df_vp) = gsub("SubID", "Donor", colnames(df_vp))

plotPercentBars( df_vp )
```

## Perform statistical tests
For each cell type
```{r cellTypeCompositionTest.neuron}
form = ~ (1|SubID) + (1|batch) + (1|round_num) + (1|HTO) + (1|Sex) + (1|Institution) + dx + scale(Age) 

fit = dream(cobj, form, as.data.frame(colData(pbObj[,i])))
fit = eBayes(fit)

topTable(fit, coef=coefs[1], number=Inf, sort.by="none")[,1:5] %>% 
  kable(digits=c(2, 2, 2, 3, 3, 2, 2), caption=coefs[1]) %>% 
  kable_classic(full_width = FALSE, html_font = "Cambria")

topTable(fit, coef=coefs[2], number=Inf, sort.by="none")[,1:5] %>%
  kable(digits=c(2, 2, 2, 3, 3, 2, 2), caption=coefs[2]) %>% 
  kable_classic(full_width = FALSE, html_font = "Cambria")

topTable(fit, coef=coefs[3], number=Inf, sort.by="none")[,1:5] %>% 
  kable(digits=c(2, 2, 2, 3, 3, 2, 2), caption=coefs[3]) %>% 
  kable_classic(full_width = FALSE, html_font = "Cambria")
```


# are too many genes being excluded?
# what does voom look like from **complete** pseudobulk??
# TODO get pH info?
# Missing Sex
# XIST genes and mito-rate
# cellTypeCompositionTest is failing
# create contrasts
# df_meta$Age[1500:1800] ages are fractions
# is there are difference between number of reads per cell type?
# + PMI and brain bank (Institution) and Ethnicity
# mvIC
# write data for QTL analysis



```{r exit2, cache=FALSE, eval=TRUE, echo=FALSE}
knitr::knit_exit()
```







