---
title: "Analysis of NPS/AD"
subtitle: 'Create Public Freeze 0 from Internal Freeze 1.5'
author: "Developed by [Gabriel Hoffman](http://gabrielhoffman.github.io/)"
date: "Run on `r Sys.time()`"
output: 
  html_document:
    toc: true
    smart: true
---


<!--- 

cd /sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/freeze_v1
ml python git pandoc
git pull
R --vanilla

system("git pull"); rmarkdown::render("create_public_release.Rmd");


# https://hoffmg01.u.hpc.mssm.edu/nps_ad/

bsub -Is -q premium -R span[hosts=1] -R rusage[mem=60000] -W 12:00 -P acc_CommonMind -n 12 bash



--->

# Load packages
```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning=FALSE,
  message=FALSE,
  error = FALSE,
  tidy = FALSE,
  dev = c("png", "pdf"),
  package.startup.message = FALSE,
  cache = FALSE,
  cache.lazy = FALSE)
```

```{r load.packages, cache=FALSE}
library(SingleCellExperiment)
library(zellkonverter)
library(DelayedArray)
library(HDF5Array)
library(dreamlet)
library(scater)
library(tidyverse)
library(kableExtra)
library(org.Hs.eg.db)

# update block size for reading h5ad file from disk
setAutoBlockSize(1e9)
```

# Load full Internal Data Freeze 1.5
```{r load.data, cache=FALSE}
outfolder = "/sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/freeze1.5_results/"
datafile = paste0(outfolder, "sceCombine_f1.5.RDS")

if( file.exists(datafile) ){
  # reading data from RDS is much faster:
  #   especially good for pipeline development
  sceCombine = readRDS( datafile )
}else{

  # FREEZE 1.5
  h5ad_file = "/sc/arion/projects/psychAD/NPS-AD/freeze1.5_rc/h5ad/220701_NPS-AD_freeze1.5_anno_meta_clean.h5ad"

  # read raw/* from h5ad file
  sce_in = readH5AD(h5ad_file, use_hdf5=TRUE, raw=TRUE, verbose=TRUE, uns=FALSE)

  # only keep singlets
  sce_in = sce_in[,sce_in$demux_type == "singlet"]

  # use `raw` as counts
  sceCombine = swapAltExp(sce_in, "raw")
  rowData(sceCombine) = rowData(sce_in)
  rownames(sceCombine) = rownames(sce_in)
  # reducedDims(sceCombine) = reducedDims(sce_in)
  reducedDim(sceCombine, "X_umap") = reducedDim(sce_in, "X_umap")
  counts(sceCombine) = assay(sceCombine, 'X')   # set counts assay to data in X
  assay(sceCombine, 'X') = NULL          # free X  

  # merge with new metadata
  df_meta = read_csv("/sc/arion/projects/psychAD/NPS-AD/freeze1.5_rc/metadata/syn26527784_latest.csv")

  # get order of matching
  i = match(sceCombine$SubID, df_meta$SubID)

  # get colums of H5AD data to exclude
  variables = c("Age","Sex", "Ethnicity")
  exclude = match( variables, colnames(colData(sceCombine)))

  # Assign new metadata
  colData(sceCombine) = cbind(colData(sceCombine)[,-exclude], df_meta[i,])

  # only save genes with unique names
  tab = table(rownames(sceCombine))
  keep = rownames(sceCombine) %in% names(tab[tab==1])
  sceCombine = sceCombine[keep,]

  saveRDS(sceCombine, file=datafile)
}
```

## Internal Data Freeze 1.5 
Includes `r length(table(sceCombine$Channel))` samples, `r length(table(sceCombine$round_num))` rounds, `r length(table(sceCombine$batch))` 10X batches, `r length(table(sceCombine$SubID))` donors, and `r format(ncol(sceCombine), big.mark=',')` cells passing QC.


## Properties
```{r proerties.combine, cache=FALSE}
# number of donors
length(table(droplevels(sceCombine$SubID)))

# number of donors
table(droplevels(sceCombine$round_num))

# cells based on Dx
table(sceCombine$AD)

# AD cases and controls
tab = with(colData(sceCombine), unique(data.frame(SubID, AD, Sex, Age, Institution)))
table(tab$AD)
table(tab$Sex)
table(tab$Institution)
hist(tab$Age)

xtabs(~AD + Sex, tab)
```


# Create subset based on AD and round_num
Inclusion criteria: 
  - Age >= 65
  - Institution is MSSM
  - round is 1,2,3,4
  - `AD` variable is 0 or 1.  `NA` is removed

```{r subset}
# Subset based on AD status and round_num
sce = sceCombine[,!is.na(sceCombine$AD) & sceCombine$round_num %in% 1:4]

# Subset to only donors >= 65 years old and in MSSM
sce = sce[,(sce$Age >= 65) & (sce$Institution=="MSSM")]

# Remove columns for public release
keep = c('Sex', 'Age', 'AD', 'SubID', 'Channel', 'round_num', 'Institution', "batch", "anno", "class", "celltype", "subtype")
colData(sce) = droplevels(colData(sce)[,keep])
```

# Sex check and filtering
```{r pb.sex, cache=TRUE}
# Sum all reads for each individual
sce$static = "all"
pb <- aggregateToPseudoBulk(sce,
      cluster_id = "static",
      sample_id  = "SubID")
```

## Show mislabels
```{r plot.sex}
# Process assays to compute log2 CPM
res.proc = processAssays( pb, ~1) 
 
# Extract merged expression and meta-data
df = extractData(res.proc, "all")

# Create a data.frame of UTY and XIST
geneID = c("Sex", "XIST", "UTY")
dfSub = df[,geneID] 
dfSub$Sex = factor(dfSub$Sex, c("Male", "Female"))

ggplot(dfSub, aes(XIST, UTY, color=Sex)) +
    geom_point() +
    theme_classic() +
    theme(aspect.ratio=1) +
    scale_color_manual(values=c("blue", "red"))
```

## Mislabeliing score
Show all and dropped donors
```{r sex.score}
# predict sex based on gene expression
fit = glm(Sex ~ XIST + UTY, dfSub, family="binomial")
sex.prob = predict(fit, type="response")

# score sex mislabeling
dfSub$score = as.integer(dfSub$Sex) -1 - sex.prob

ggplot(dfSub[order(abs(dfSub$score)),], 
  aes(XIST, UTY, color=abs(score))) +
    geom_point() +
    theme_classic() +
    theme(aspect.ratio=1) +
    scale_color_gradient(low="black", high="orange", limits=c(0, 1))

drop = abs(dfSub$score) > 0.5
table(drop)

ggplot(dfSub[drop,], aes(XIST, UTY, color=abs(score))) +
    geom_point() +
    theme_classic() +
    theme(aspect.ratio=1) +
    scale_color_gradient(low="black", high="orange", limits=c(0, 1))
```


# Write H5AD for public release
```{r write}
sce = sce[,sce$SubID %in% df$Row.names[!drop]]
colData(sce) = droplevels(colData(sce))

# write RDS
# outfile = "/sc/arion/projects/psychAD/NPS-AD/public_release_0/PsychAD_r0_Sept20_22.RDS"
# saveRDS(sce, outfile)

# # write H5AD
# outfile = "/sc/arion/projects/psychAD/NPS-AD/public_release_0/PsychAD_r0_Sept16_22.h5ad"
# writeH5AD(sce, outfile, compression="lzf")
```

```{r write.chunks, eval=FALSE}
vec = seq(1, ncol(sce))
chunk_length <- 50000     
chunks = split(vec, ceiling(seq_along(vec) / chunk_length))

outprefix = "/sc/arion/projects/psychAD/NPS-AD/public_release_0/PsychAD_r0_Sept22_22"

res = lapply(names(chunks), function(id){
  message(id)
  outfile = paste0(outprefix, '_chunk', id, ".h5ad")
  sceSub = sce[,chunks[[id]]]
  writeH5AD(sceSub, outfile, compression="none")
  })
```

## Bash code to combine H5AD files
```{python cat, eval=FALSE}
# zellkonverter::writeH5AD() fails with 1.5M cells
# So write in batches.
# Later, concatenate the chunks in python
# Do on high memory node
# Need to use AnnData > 0.8.0
conda activate /hpc/users/hoffmg01/.cache/R/basilisk/1.8.0/0

SRC=/sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/concat_h5ad.py

cd /sc/arion/projects/psychAD/NPS-AD/public_release_0/ 
echo $(ls /sc/arion/projects/psychAD/NPS-AD/public_release_0/PsychAD_r0_Sept22_22_chunk*.h5ad) | tr ' ' '\n' > list.txt

cd /hpc/users/hoffmg01/.cache/R/basilisk/1.8.0/0/pkgs/
OUTFILE=/sc/arion/projects/psychAD/NPS-AD/public_release_0/PsychAD_r0_Sept16_22.h5ad 
python $SRC -i /sc/arion/projects/psychAD/NPS-AD/public_release_0/list.txt -o $OUTFILE
```

Remove X
Remove static
UMAP
annotation


```{r save}
# outfile = "/sc/arion/projects/psychAD/NPS-AD/public_release_0/PsychAD_r0_Sept16_22_cells.tsv"
# write(colnames(sce), file=outfile)
```

# Public Data Freeze 0 
Includes `r length(table(sce$Channel))` samples, `r length(table(sce$round_num))` rounds, `r length(table(sce$batch))` 10X batches, `r length(table(sce$SubID))` donors, and `r format(ncol(sce), big.mark=',')` cells passing QC.

## Properties
```{r proerties, cache=FALSE}
# number of donors
length(table(droplevels(sce$SubID)))

# number of donors
table(droplevels(sce$round_num))

# cells based on Dx
table(sce$AD)

# AD cases and controls
tab = with(colData(sce), unique(data.frame(SubID, AD, Sex, Institution, Age)))
table(tab$AD)
table(tab$Sex)
table(tab$Institution)

xtabs(~AD + Sex, tab)
```






