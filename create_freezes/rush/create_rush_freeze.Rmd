---
title: "Analysis of NPS/AD"
subtitle: 'Create Merged Rush freeze'
author: "Developed by [Gabriel Hoffman](http://gabrielhoffman.github.io/)"
date: "Run on `r Sys.time()`"
output: 
  html_document:
    toc: true
    smart: true
---


<!--- 

cd /sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/create_freezes/rush
ml python git pandoc
git pull
R --vanilla

system("git pull origin master"); rmarkdown::render("create_rush_freeze.Rmd");


# https://hoffmg01.hpc.mssm.edu/nps_ad/create_freezes/rush

bsub -Is -q premium -R span[hosts=1] -R rusage[mem=60000] -W 12:00 -P acc_CommonMind -n 12 bash



--->

# Load packages
```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning=FALSE,
  message=FALSE,
  error = FALSE,
  tidy = FALSE,
  dev = c("png", "pdf"),
  package.startup.message = FALSE,
  cache = FALSE,
  cache.lazy = FALSE)
```

```{r load.packages, cache=FALSE}
library(SingleCellExperiment)
library(zellkonverter)
library(DelayedArray)
library(HDF5Array)
library(dreamlet)
library(scater)
library(tidyverse)
library(kableExtra)
library(org.Hs.eg.db)

# update block size for reading h5ad file from disk
setAutoBlockSize(1e9)
```

# Load full Internal Public Freeze 0
```{r load.data, cache=FALSE}
outfolder = "/sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/public_freeze_0_results/"
datafile = paste0(outfolder, "sceCombine_rush0.RDS")

if( file.exists(datafile) ){
  # reading data from RDS is much faster:
  #   especially good for pipeline development
  sceCombine = readRDS( datafile )
}else{

  # Public freeze 0
  h5ad_file = "/sc/arion/projects/psychAD/NPS-AD/freeze2_rc/h5ad/221210_NPS-AD_freeze2_R_pass3_anno.h5ad"

  # read raw/* from h5ad file
  sce_in = readH5AD(h5ad_file, use_hdf5=TRUE, raw=TRUE, verbose=TRUE, uns=FALSE)

  # use `raw` as counts
  sceCombine = swapAltExp(sce_in, "raw")
  rowData(sceCombine) = rowData(sce_in)
  rownames(sceCombine) = rownames(sce_in)
  reducedDim(sceCombine, "X_umap") = reducedDim(sce_in, "X_umap")
  reducedDim(sceCombine, "X_pca") = reducedDim(sce_in, "X_pca")
  reducedDim(sceCombine, "X_pca_regressed_harmony") = reducedDim(sce_in, "X_pca_regressed_harmony")
  counts(sceCombine) = assay(sceCombine, 'X')   # set counts assay to data in X
  assay(sceCombine, 'X') = NULL          # free X  

  # merge with new metadata
  df_meta = read_csv("/sc/arion/projects/psychAD/NPS-AD/freeze1_rc/metadata/syn26527784_latest.csv")

  # get order of matching
  i = match(sceCombine$SubID, df_meta$SubID)

  # Assign new metadata
  colData(sceCombine) = cbind(colData(sceCombine), df_meta[i,])

  # only save genes with unique names
  tab = table(rownames(sceCombine))
  keep = rownames(sceCombine) %in% names(tab[tab==1])
  sceCombine = sceCombine[keep,]

  saveRDS(sceCombine, file=datafile)
}
```

## Public freeze 0, initial
Includes `r length(table(sceCombine$Channel))` samples, `r length(table(sceCombine$round_num))` rounds, `r length(table(sceCombine$poolID))` 10X batches, `r length(table(sceCombine$SubID))` donors, and `r format(ncol(sceCombine), big.mark=',')` cells passing QC.

## Properties
```{r proerties.combine, cache=FALSE}
# number of donors
length(table(droplevels(sceCombine$SubID)))

# cells based on Dx
table(sceCombine$AD)

# AD cases and controls
tab = with(colData(sceCombine), unique(data.frame(SubID, AD, Sex, Age)))
table(tab$AD)
table(tab$Sex)
hist(tab$Age)

xtabs(~AD + Sex, tab)
```

Filter by Sex_chr_aneuploidy
```{r subset}
# and no Sex_chr_aneuploidy, based on genotype
# if no genotype available, reports NA
exclude = replace_na(sceCombine$Sex_chr_aneuploidy, FALSE)
sce = sceCombine[,!exclude ]
```

# Sex check and filtering
```{r pb.sex, cache=TRUE}
# Sum all reads for each individual
sceCombine$static = "all" 
pb <- aggregateToPseudoBulk(sceCombine,
      cluster_id = "static",
      sample_id  = "SubID",
      BPPARAM=SnowParam(6))
```

## Show mislabels
```{r plot.sex}
# Process assays to compute log2 CPM
res.proc = processAssays( pb, ~ 1) 
  
# Extract merged expression and meta-data
df = extractData(res.proc, "all")

# Create a data.frame of UTY and XIST
geneID = c("Row.names", "Sex", "XIST", "UTY")
dfSub = df[,geneID] 
dfSub$Sex = factor(dfSub$Sex, c("Male", "Female"))

ggplot(dfSub, aes(XIST, UTY, color=Sex)) +
    geom_point() +
    theme_classic() +
    theme(aspect.ratio=1) +
    scale_color_manual(values=c("blue", "red"))
```

## Mislabeling score
Show all and dropped donors
```{r sex.score}
# predict sex based on gene expression
fit = glm(Sex ~ XIST + UTY, dfSub, family="binomial")
sex.prob = predict(fit, type="response")
 
# score sex mislabeling
dfSub$score = as.integer(dfSub$Sex) -1 - sex.prob

ggplot(dfSub[order(abs(dfSub$score)),], 
  aes(XIST, UTY, color=abs(score))) +
    geom_point() +
    theme_classic() +
    theme(aspect.ratio=1) +
    scale_color_gradient(low="black", high="orange", limits=c(0, 1))

drop = abs(dfSub$score) > 0.5
table(drop)

# ggplot(dfSub[drop,], aes(XIST, UTY, color=abs(score))) +
#     geom_point() +
#     theme_classic() +
#     theme(aspect.ratio=1) +
#     scale_color_gradient(low="black", high="orange", limits=c(0, 1))
```

```{r kbl}
dfSub %>%
  filter(abs(score) > 0.5) %>%
  kbl %>%
  kable_styling(full_width=FALSE)
```  
# Write H5AD for public release
```{r write}
sce$static = c()
sce = sce[,sce$SubID %in% df$Row.names[!drop]]
colData(sce) = droplevels(colData(sce))
```


```{r write.whole, eval=FALSE}
outfile = "/sc/arion/projects/psychAD/NPS-AD/public_release_0/Rush_Dec_19_2022.h5ad"
writeH5AD(sce, outfile, compression="lzf")
```

```{r write.chunks, eval=FALSE}

# this some how avoids a python error during concatenation
# pandas.errors.InvalidIndexError: 
#    Reindexing only valid with uniquely valued Index objects
sceCopy = SingleCellExperiment( list(counts=counts(sce)),
          rowData = rowData(sce),
          colData = colData(sce)[,1:ncol(colData(sce))],
          reducedDims = reducedDims(sce))

vec = seq(1, ncol(sceCopy))
chunk_length <- 100000     
chunks = split(vec, ceiling(seq_along(vec) / chunk_length))

outprefix = "/sc/arion/projects/psychAD/NPS-AD/public_release_0/Rush_Dec_19_2022"

res = lapply(names(chunks), function(id){
  message(id)
  outfile = paste0(outprefix, '_chunk', id, ".h5ad")
  sceSub = sceCopy[,chunks[[id]]]
  writeH5AD(sceSub, outfile, compression="none")
  })
```

## Bash code to combine H5AD files
```{python cat, eval=FALSE}
# zellkonverter::writeH5AD() fails with 1.5M cells
# So write in batches.
# Later, concatenate the chunks in python
# Do on high memory node
# Need to use AnnData > 0.8.0
conda activate /hpc/users/hoffmg01/.cache/R/basilisk/1.8.0/0

SRC=/sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/concat_h5ad.py

cd /sc/arion/projects/psychAD/NPS-AD/public_release_0/ 
echo $(ls /sc/arion/projects/psychAD/NPS-AD/public_release_0/Rush_Dec_19_2022_chunk*.h5ad) | tr ' ' '\n' > list.txt

cd /hpc/users/hoffmg01/.cache/R/basilisk/1.8.0/0/pkgs/
OUTFILE=/sc/arion/projects/psychAD/NPS-AD/public_release_0/Rush_Dec_19_2022.h5ad 
python $SRC -i /sc/arion/projects/psychAD/NPS-AD/public_release_0/list.txt -o $OUTFILE
```



```{r save, eval=FALSE}
# outfile = "/sc/arion/projects/psychAD/NPS-AD/public_release_0/PsychAD_r0_Sept16_22_cells.tsv"
# write(colnames(sce), file=outfile)
```

# Public Data Freeze 0 
Includes `r length(table(sce$Channel))` samples, `r length(table(sce$round_num))` rounds, `r length(table(sce$poolID))` 10X batches, `r length(table(sce$SubID))` donors, and `r format(ncol(sce), big.mark=',')` cells passing QC.

## Properties
```{r proerties, cache=FALSE}
# number of donors
length(table(droplevels(sce$SubID)))

# number of donors
table(droplevels(sce$round_num))

# cells based on Dx
table(sce$AD)

# AD cases and controls
tab = with(colData(sce), unique(data.frame(SubID, AD, Sex, Age)))
table(tab$AD)
table(tab$Sex)

xtabs(~AD + Sex, tab)
```

# Session Info
<details>
```{r sessioninfo, cache=FALSE}
sessionInfo()
```
</details>





