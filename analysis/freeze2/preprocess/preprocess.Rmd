---
title: "Preprocess H5AD files"
subtitle: 'Save pseudobulk, etc'
author: "Developed by [Gabriel Hoffman](http://gabrielhoffman.github.io/)"
date: "Run on `r Sys.time()`"
output: 
  html_document:
    toc: true
    smart: true
params:
  DATASET: NULL
---


<!--- 

~ Sex + scale(Age) + scale(PMI) + 
  Plaque_mean + 
  Cognitive_Resilience + 
  (1|BRAAK_AD) +
  (1|CERAD) + 
  (1|CDRScore) + 
  (1|MajorDisease) + 
  (1|DementiaType) + 
  (1|cogdx) + 
  log(n_genes)


# batching
cd /sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/analysis/freeze2/preprocess/

# ./submit_preproc.R --cohort test
sed 's/$1/RUSH/g' ./submit_preproc.sh | bsub
sed 's/$1/HBCC/g' ./submit_preproc.sh | bsub
sed 's/$1/MSSM/g' ./submit_preproc.sh | bsub
sed 's/$1/AGING/g' ./submit_preproc.sh | bsub


# bsub -Is -q premium -R span[hosts=1] -R rusage[mem=50000] -W 72:00 -P acc_CommonMind -n 12 bash

# bsub -Is -q premium -R span[hosts=1] -R rusage[mem=30000] -W 64:00 -P acc_CommonMind -n 12 bash


cd /sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/analysis/freeze2/preprocess/
ml python git pandoc gcc/11.2.0
# git pull origin master
R --vanilla --no-restore

library(rmarkdown)
library(tidyverse)

path = "/sc/arion/projects/psychAD/NPS-AD/freeze2_rc/h5ad_final/"

h5ad_files = c(
RUSH = "RUSH_2023-09-12_16_13.h5ad", 
HBCC = "HBCC_2023-09-12_16_28.h5ad",
MSSM = "MSSM_2023-09-12_17_04.h5ad",
FULL = "FULL_2023-09-12_18_32.h5ad",
AGING = "AGING_2023-09-12_20_35.h5ad")

h5ad_files = sapply(h5ad_files, function(x) paste0(path, x))

# create_job = function(x){
#   # system("git pull origin master");

#   tmp.dir = paste0("/sc/arion/scratch/hoffmg01/", x, "_", round(runif(1)*1e7))
#   dir.create(tmp.dir)
#   setwd(tmp.dir)

#   # create tmp Rmd for each dataset
#   fldr = "/sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/analysis/freeze2/preprocess/"
#   file.orig = paste0(fldr, "preprocess.Rmd")
#   file = paste0(fldr, "preprocess_", x,".Rmd") 
#   file.copy(file.orig, file, overwrite=TRUE)

#   # x %>% 
#   #   walk(function(x) render(file,
#   #           params = list(DATASET = h5ad_files[x]),
#   #           output_file = paste0(fold, "/preprocess_", x, ".html")))
# }

run = function(x){

  # copy to process_{DATASET}.Rmd and execute
  fldr = "/sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/analysis/freeze2/preprocess/"
  file1 = paste0(fldr, "preprocess.Rmd")
  file2 = paste0(fldr, "preprocess_", x,".Rmd")

  file.copy(file1, file2, overwrite=TRUE)

  render(file2,
          params = list(DATASET = h5ad_files[x]),
          output_file = paste0(fldr, "/preprocess_", x, ".html"))
}

names(h5ad_files) %>%
  walk(create_job)
  

run("RUSH")


run("HBCC")


run("MSSM")


# run("FULL")


run("AGING")






# https://hoffmg01.hpc.mssm.edu/nps_ad/analysis/freeze2/preprocess/preprocess_FULL.html


params = list(DATASET = h5ad_files["AGING"])

params = list(DATASET = h5ad_files["FULL"])


params = list(DATASET = h5ad_files["MSSM"])


params = list(DATASET = h5ad_files["RUSH"])


params = list(DATASET = h5ad_files["HBCC"])


# Try to merge MSSM
# bsub -Is -q premium -R span[hosts=1] -R rusage[mem=60790] -W 12:00 -P acc_CommonMind -n 30 bash



--->


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE,
  warning=FALSE,
  message=FALSE,
  error = FALSE,
  tidy = FALSE,
  dev = c("png", "pdf"),
  package.startup.message = FALSE,
  cache = FALSE,
  cache.lazy = FALSE)
```

 <font size="5">__Evaluating dataset: `r names(params$DATASET)`__</font>


# Loading
## Libraries
```{r load.packages, cache=FALSE}
suppressPackageStartupMessages({
library(SingleCellExperiment)
library(zellkonverter)
library(dreamlet)
library(zenith)
library(DelayedArray)
library(GSEABase)
library(scater)
library(tidyverse)
library(ggplot2)
library(cowplot) 
library(org.Hs.eg.db)
library(R.utils)
library(RhpcBLASctl)
})
omp_set_num_threads(1)
```

## H5AD
```{r load.data}
sce = readH5AD(params$DATASET, use_hdf5=TRUE, verbose=TRUE)
assayNames(sce)[1] = "counts"

# Create pseudo-bulk SingleCellExperiment
cluster_id_options = c("bulk", "class", "subclass", "subtype")
sample_id_options = c("SubID") #c("Channel", "SubID")

sce$bulk = "bulk"

# order of cell types used for plotting
# Compute pseudobulk at multiple levels
ctorder = c('EN_L2_3_IT', 'EN_L3_5_IT_1', 'EN_L3_5_IT_2', 'EN_L3_5_IT_3', 'EN_L5_ET', 'EN_L5_IT', 'EN_L5_6_NP', 'EN_L6B', 'EN_L6_CT', 'EN_L6_IT', "EN_L6_IT_1", "EN_L6_IT_2", 'EN_NF', 'IN_ADARB2', 'IN_LAMP5', 'IN_LAMP5_LHX6', 'IN_LAMP5_RELN', 'IN_PVALB', 'IN_PVALB_CHC', 'IN_SST', 'IN_VIP', 'Oligo', 'OPC', 'Astro', 'Micro', 'PVM', 'Micro_PVM', 'CD8_T', 'PC', 'VLMC','SMC', 'Endo', "Immune")

included = (levels(sce$subclass) %in% ctorder)

if( any(!included) ){
  stop("subclass levels not in ctorder")
}

# only keep ctorder entries that are in sce$subclass
ctorder = ctorder[ctorder %in% levels(sce$subclass)]

bpparam = SnowParam(4)
```


# Prepare covariates
```{r prep.covs}
augment_data = function(pb){

  # Combine and modify disease phenotypes
  #######################################
  cn1 = c( 'MCI', 'SCZ', 'AD')
  cn2 = c( 'DLBD', 'Dementia', 'FTD')
  cn_bd = c("BD_unspecific", "BD_I", "BD_II")
  cn_all = c(cn1, cn2, cn_bd)

  info = data.frame(colData(pb)[,cn_all])
  info[is.na(info)] = 0

  # code BD
  info$BD = apply(info[,cn_bd], 1, function(x) ifelse(length(unique(x)) == 1, 0, 1))

  for(id in colnames(info)){
    info[,id] = factor(c("no", id)[info[,id]+1], levels=c("no", id))
  }

  # set 1
  cn1 = c(cn1, "BD")
  ph1 = apply(info[,cn1], 1, function(x) paste(x[x!="no"], collapse="/"))
  ph1[ph1 == "SCZ/AD"] = "AD"
  ph1[ph1 == "MCI/SCZ"] = "SCZ"
  ph1[ph1 == ""] = "none"
  # sort(table(ph1))
  pb$MajorDisease = factor(ph1)

  # set2
  ph2 = apply(info[,cn2], 1, function(x) paste(x[x!="no"], collapse="/"))
  ph2[ph2 == "Dementia/FTD"] = "FTD"
  ph2[ph2 == "DLBD/Dementia"] = "DLBD"
  ph2[ph2 == ""] = "none"
  # sort(table(ph2))
  pb$DementiaType = factor(ph2)

  if( length(unique(pb$DementiaType)) == 1){
    pb$DementiaType = c()
  }
  if( length(unique(pb$MajorDisease)) == 1){
    pb$MajorDisease = c()
  }

  # metrics
  if( any(!is.na(pb$BRAAK_AD)) ){
    pb$mod_BRAAK_AD = factor(as.character(pb$BRAAK_AD))
    pb$mod_BRAAK_AD[is.na(pb$mod_BRAAK_AD)] = 2
  }

  if( any(!is.na(pb$Plq_Mn)) ){
    pb$mod_Plq_Mn = pb$Plq_Mn
    pb$mod_Plq_Mn[is.na(pb$mod_Plq_Mn)] = mean(pb$mod_Plq_Mn, na.rm=TRUE)
  }

  if( any(!is.na(pb$CERAD)) ){  
    pb$mod_CERAD = pb$CERAD
    pb$mod_CERAD[is.na(pb$mod_CERAD)] = mean(pb$mod_CERAD, na.rm=TRUE)
  }

  if( any(!is.na(pb$CDRScore)) ){
    pb$mod_CDRScore = pb$CDRScore
    pb$mod_CDRScore[is.na(pb$mod_CDRScore)] = mean(pb$mod_CDRScore, na.rm=TRUE)
  }

  if( any(!is.na(pb$Cognitive_Resilience)) ){
    pb$mod_Cognitive_Resilience = pb$Cognitive_Resilience
    pb$mod_Cognitive_Resilience[is.na(pb$mod_Cognitive_Resilience)] = mean(pb$mod_Cognitive_Resilience, na.rm=TRUE)
  }

  # Merge with technical metadata
  #------------------------------
  prefix = "/sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/analysis/freeze2/metadata/"
  file = paste0(prefix, "Bioassay_Table_Pool_Wet.tsv")
  df_cov_wet = read_tsv( file, show_col_types = FALSE )

  file = paste0(prefix, "Bioassay_Table_Pool_Dry.tsv")
  df_cov_dry = read_tsv( file, skip=2,show_col_types = FALSE)

  # donor list
  donorList = strsplit(df_cov_dry$EXPECTED_DONORS, " ")
  donors = unique(unlist(donorList))

  # numeric columns
  cols =  df_cov_dry %>% 
      summarise_all(class) %>% 
      gather(col_name, col_type) %>%
      filter(col_type == "numeric") %>%
      pull(col_name)

  # extact mean value per donor
  df = lapply(donors, function(id){

    # which row
    i = which(sapply(donorList, function(x) id %in% x))

    df_cov_dry[i,cols] %>%
      colMeans %>%
      data.frame %>%
      t() %>%
      data.frame(ID = id, .)
  })
  df = do.call(rbind, df) %>% as_tibble
  df$REPLICATE = c()

  # remove duplicated cols
  cn = gsub("...\\d+", "", colnames(df))
  df = df[,!duplicated(cn)]
  colnames(df) = gsub("...\\d+", "", colnames(df))

  i = match(colnames(pb), df$ID)
  colData(pb) = cbind(colData(pb), df[i,])

  # add cogdx for rush
  #-------------------
  if( pb$Source[1] == "R" ){
    prefix = "/sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/analysis/freeze2/metadata/"
    file = paste0(prefix, "clinical_metadata_full.csv")
    df = read_csv( file, show_col_types = FALSE )

    i = match(colnames(pb), df$SubID)
    colData(pb) = cbind(colData(pb), df[i,"cogdx",drop=FALSE])

    pb$mod_cogdx = factor(pb$cogdx)
    pb$mod_cogdx[is.na(pb$mod_cogdx)] = 4
  }

  pb
}
```


# Compute pseudobulk at multiple levels
```{r combineData, message=TRUE, eval=TRUE}
for(cluster_id in cluster_id_options ){
  for(sample_id in sample_id_options ){

    # Compute pseudobulk for each cell type
    pb = aggregateToPseudoBulk(sce,
      assay = "counts", 
      cluster_id = cluster_id,
      sample_id = sample_id,
      BPPARAM = bpparam)

    # augment pseudobulk with additional metadata
    pb = augment_data( pb )

    filePrefix = paste0("/sc/arion/projects/psychAD/NPS-AD/freeze2_rc/pseudobulk/", gsub(".h5ad$", "", basename(params$DATASET)), "_PB_", sample_id, "_", cluster_id)

    # Save as RDS
    saveRDS(pb, file = paste0(filePrefix, ".RDS"))

    # Save as H5AD
    writeH5AD( pb, file = paste0(filePrefix, ".h5ad"), compression = "lzf" )

    # precision weights
    W.list = pbWeights(sce,
      cluster_id = cluster_id,
      sample_id = sample_id, 
      method = "delta",
      maxRatio = 100)

    filePrefix = paste0("/sc/arion/projects/psychAD/NPS-AD/freeze2_rc/pseudobulk/", gsub(".h5ad$", "", basename(params$DATASET)), "_pbWeights_", sample_id, "_", cluster_id)

    # Save as RDS
    saveRDS(W.list, file = paste0(filePrefix, ".RDS"))
  }
}
```



# Compute `processAssays()` at multiple levels
```{r processAssays, eval=TRUE, message=FALSE, warning=TRUE}
rm(bpparam)
bpparam = SnowParam(4)

for(cluster_id in cluster_id_options ){
  for(sample_id in sample_id_options ){

    message(cluster_id, ' ', sample_id)

    txt = paste(cluster_id, sample_id, "\n")
    outfile = paste0('logs/', basename(params$DATASET), '.log')
    write(txt, file=outfile, append=TRUE)

    # Read pseudobulk RDS 
    filePrefix = paste0("/sc/arion/projects/psychAD/NPS-AD/freeze2_rc/pseudobulk/", gsub(".h5ad$", "", basename(params$DATASET)), "_PB_", sample_id, "_", cluster_id)
    pb = readRDS(paste0(filePrefix, ".RDS"))

    # formula
    form = ~ Sex + scale(Age) + scale(PMI) + (1|mod_BRAAK_AD) + mod_Plq_Mn + (1|mod_CERAD) + (1|mod_CDRScore) + mod_Cognitive_Resilience + (1|MajorDisease) + (1|DementiaType) + (1|mod_cogdx) + log(n_genes) 
    if( sample_id == "Channel"){
      form = update(form,  ~ . + (1|SubID))
    }

    # remove absent terms
    if( nlevels(pb$Source) == 1 && levels(pb$Source) == "R"){
      form = update(form,  ~ . - mod_Plq_Mn - (1|mod_CDRScore) - mod_Cognitive_Resilience)
    }
    if( nlevels(pb$Source) == 1 && levels(pb$Source) == "M"){
      form = update(form,  ~ . - (1|mod_cogdx))
    }
    if( nlevels(pb$Source) == 1 && levels(pb$Source) == "H"){
      form = update(form,  ~ . - (1|mod_BRAAK_AD) - mod_Plq_Mn - (1|mod_CERAD) - (1|mod_CDRScore) - (1|mod_Cognitive_Resilience) - (1|DementiaType) - (1|mod_cogdx) - mod_Cognitive_Resilience)
    }
    if( nlevels(pb$Source) == 2){
      form = update(form,  ~ . - (1|MajorDisease) - (1|DementiaType) - (1|mod_cogdx)) 
    }  

    # Read weights
    filePrefix = paste0("/sc/arion/projects/psychAD/NPS-AD/freeze2_rc/pseudobulk/", gsub(".h5ad$", "", basename(params$DATASET)), "_pbWeights_", sample_id, "_", cluster_id)
    W.list = readRDS(paste0(filePrefix, ".RDS"))

    # processAssays
    res.proc = processAssays( pb, form, BPPARAM = bpparam, weightsList = W.list)
    flush(stderr())

    # Save processed object to RDS
    file = paste0("/sc/arion/projects/psychAD/NPS-AD/freeze2_rc/processAssays/", gsub(".h5ad$", "", basename(params$DATASET)), "_processAssays_", sample_id, "_", cluster_id, ".RDS")
    saveRDS(res.proc, file)

    # Residuals
    if( sample_id == "SubID" ){
      message("residuals...")
      fit = dreamlet(res.proc, form, 
                      BPPARAM = bpparam )
      flush(stderr())

      for( CT in assayNames(res.proc) ){
        message(paste0("   ", CT))
        # residuals
        file = paste0("/sc/arion/projects/psychAD/NPS-AD/freeze2_rc/residuals/", gsub(".h5ad$", "", basename(params$DATASET)), "_residuals_", sample_id, "_", cluster_id, "_", CT, ".tsv")

        data = format(residuals(fit[[CT]]), digits=5)
        write.table( data, file=file, quote=FALSE, sep="\t")
        gzip(file, overwrite=TRUE)

        # pearson residuals
        file = paste0("/sc/arion/projects/psychAD/NPS-AD/freeze2_rc/residuals/", gsub(".h5ad$", "", basename(params$DATASET)), "_residualsPearson_", sample_id, "_", cluster_id, "_", CT, ".tsv")

        data = residuals(fit[[CT]], res.proc[[CT]], type="pearson")        
        data = format(data, digits=5)
        write.table( data, file=file, quote=FALSE, sep="\t")
        gzip(file, overwrite=TRUE)
      }
      rm(data)
      gc()
    }

    rm(pb)
    rm(res.proc)
    gc()
  }
}
```



# Summarizing data
## UMAP
```{r umap1}
plotProjection(sce, "X_umap", "class")  + ggtitle("class")
```

```{r umap2}
plotProjection(sce, "X_umap", "subclass", order=ctorder)  + ggtitle("subclass")
```

```{r umap3}
plotProjection(sce, "X_umap", "subtype")  + ggtitle("subtype")
```

## Summarize cell counts
```{r summarize.cell.counts, fig.width=5}
# cells per Channel
colData(sce)$Channel %>% 
  table %>% 
  hist(main=paste0("Cell counts per Channel: mean=", format(mean(.), digits=2), ", median = ", format(median(.), digits=2)))

colData(sce)$SubID %>% 
  table %>% 
  hist(main=paste0("Cell counts per SubID: mean=", format(mean(.), digits=2), ", median = ", format(median(.), digits=2)))

# Number of cells observed per Channel
colData(sce) %>%
  xtabs( ~ Channel + subclass,.) %>%
  as_tibble %>%
  pivot_longer(cols=Channel) %>%
  mutate(subclass = factor(subclass, ctorder)) %>%  
  ggplot(aes(subclass, n, fill=subclass)) + 
    geom_violin(color = NA) + 
    geom_boxplot(width=.1, outlier.size=.1) +
    theme_classic() + 
    theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5),
      legend.position="none") + 
    scale_y_log10() +
    coord_flip() +
    ylab("Number of cells observed per Channel") +
    xlab('')

# Number of cells observed per Subject
fig.cells_subject = colData(sce) %>%
  xtabs( ~ SubID + subclass,.) %>%
  as_tibble %>%
  pivot_longer(cols=SubID) %>%
  mutate(subclass = factor(subclass, ctorder)) %>%  
  ggplot(aes(subclass, n, fill=subclass)) + 
    geom_violin(color = NA) + 
    geom_boxplot(width=.1, outlier.size=.1) +
    theme_classic() + 
    theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5),
      legend.position="none") + 
    scale_y_log10() +
    coord_flip() +
    ylab("Number of cells observed per Subject") +
    xlab('')
fig.cells_subject    
```

```{r read.pseudobulk}
filePrefix = paste0("/sc/arion/projects/psychAD/NPS-AD/freeze2_rc/pseudobulk/", gsub(".h5ad$", "", basename(params$DATASET)), "_PB_", "Channel", "_", "subclass")

# Read from RDS
pb = readRDS(paste0(filePrefix, ".RDS"))
```

## Summarize read counts
```{r summarize.read.counts}
# extract read counts for each Channel
df_counts = lapply( assayNames(pb), function(x){
  data = assay(pb, x)

  data.frame(celltype = x, ID = colnames(data), readCounts = colSums(data))
})
df_counts = do.call(rbind, df_counts)
df_counts$celltype = factor(df_counts$celltype, ctorder)  

ggplot(df_counts, aes(celltype, readCounts, fill=celltype)) +  
    geom_violin(color = NA) + 
    geom_boxplot(width=.1, outlier.size=.1) +
    theme_classic() + 
    theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5),
      legend.position="none") + 
    scale_y_log10() +
    coord_flip() +
    ylab("Number of reads observed for each Channel") +
    xlab('') +
    ggtitle('Reads per cell cluster for each Channel')

# extract cell counts
df_rate = cellCounts(pb) %>%
            as.data.frame %>%
            mutate(ID = rownames(.))  %>% 
            pivot_longer(cols=-ID, values_to="ncells", names_to="celltype") %>%
            mutate(celltype = factor(celltype, ctorder))  

# plot reads per cell
inner_join(df_counts, df_rate, by=c("celltype", "ID")) %>%
  ggplot(aes(celltype, readCounts/ncells, fill=celltype)) +  
    geom_violin(color = NA) + 
    geom_boxplot(width=.1, outlier.size=.1) +
    theme_classic() + 
    theme(aspect.ratio=1, plot.title = element_text(hjust = 0.5),
      legend.position="none") + 
    scale_y_log10() +
    coord_flip() +
    ylab('Reads per cell') +
    xlab('') +
    ggtitle('Reads per cell for each Channel')
```


## Cell type specificity
```{r cellTypeSpecificity}
df_cellScore = cellTypeSpecificity( pb )
 
plotViolin(df_cellScore, assays=ctorder)  
```


### Show cell markers
```{r cellMarkers, echo=FALSE, eval=FALSE}
genes = c('RBFOX3', 'MEG3', 'SLC17A7',
'RBFOX3', 'MEG3', 'GAD1', 'GAD2', 'GRIK1',
'SST',
'PVALB',
'VIP',
'SLC1A3', 'GFAP', 'APOE', 'SLC1A2', 'SLC14A1',
'PLP1', 'MAG', 'MBP',
'PDGFRA', 'VCAN',
'FLT1', 'CLDN5',
'PDGFRB',
'TGFBR1', 'DOCK8', 'CD74', 'CSF1R', 'MS4A6A', 'PLXDC2')
 
df_genes = AnnotationDbi::select(org.Hs.eg.db, genes, "ENSEMBL", "SYMBOL")

df_sub = df_cellScore[rownames(df_cellScore) %in% df_genes$ENSEMBL,]
idx = match(rownames(df_sub), df_genes$ENSEMBL)
rownames(df_sub) = df_genes$SYMBOL[idx]

plotPercentBars(df_cellScore, genes=unique(genes), assays=ctorder)  
```

```{r heatmap, fig.height=7, fig.width=7, echo=FALSE, eval=FALSE}
dreamlet::plotHeatmap(df_cellScore, genes=unique(genes), assays=ctorder)  
```


# Process data: log2 CPM + voom precision weights
```{r voom}
# Normalize and apply voom
form = ~ (1|SubID) + (1|poolID) + (1|Sex) + scale(Age) + (1|date) + (1|flowcell) + log(n_genes)

res.proc = processAssays( pb, form, BPPARAM = bpparam)
```

```{r voom.plot, fig.height=15, fig.width=10, cache=TRUE}
plotVoom( res.proc, ncol=4, assays=ctorder) 
```


# Variance Partitioning Analysis
```{r varPart}
form = ~ (1|SubID) + (1|poolID) + (1|Sex) + scale(Age) + (1|date) + (1|flowcell) + log(n_genes)

res.vp = fitVarPart(res.proc, form, BPPARAM = bpparam)
```



```{r vp.plot, fig.height=15, fig.width=10}
plotVarPart( sortCols(res.vp), label.angle=45, ncol=4, assays=ctorder )  
```



# Correlation with and between donors
```{r within_btw, fig.height=10, fig.width=10}
source("/sc/arion/projects/CommonMind/hoffman/NPS-AD/work/nps_ad/common_analyses.R")
 
fig = eval_within_across_donor( res.proc, "SubID" )

fig + theme(panel.grid.minor = element_blank(),
            panel.grid.minor.y = element_blank())
```


# Session Info
<details>
```{r sessioninfo, cache=FALSE}
sessionInfo()
```
</details>

